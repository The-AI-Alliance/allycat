
## All of the settings below are optional
## Uncomment to specify a value

## ----------- workspace to save downloaded files / artifacts -----------
# WORKSPACE_DIR = 'workspace

## --------  Crawl settings  -----------
## how long to wait between requests (in seconds)
# WAITTIME_BETWEEN_REQUESTS = 0.1

## ----------- Embedding models -----------
## Find embedding models: https://huggingface.co/spaces/mteb/leaderboard

## size : 61 M
# EMBEDDING_MODEL = 'ibm-granite/granite-embedding-30m-english'
# EMBEDDING_LENGTH = 384

## size: 129 M
# EMBEDDING_MODEL = 'BAAI/bge-small-en-v1.5'
# EMBEDDING_LENGTH = 384

## Size : 219 M
# EMBEDDING_MODEL = 'ibm-granite/granite-embedding-107m-multilingual'
# EMBEDDING_LENGTH = 384

## size : 471 M
# EMBEDDING_MODEL = 'intfloat/multilingual-e5-small'
# EMBEDDING_LENGTH = 384


## ----------- Chunking  -----------
# CHUNK_SIZE = 512
# CHUNK_OVERLAP = 20

## ------- LLMs --------
## Running locally using Ollama 
# LLM_RUN_ENV = 'local_ollama'
# LLM_MODEL = 'ollama/gemma3:1b'

## Running on Nebius 
# LLM_RUN_ENV = 'nebius'
# NEBIUS_API_KEY = your_nebius_api_key
# LLM_MODEL = 'nebius/Qwen/Qwen3-30B-A3B'

## Running on Replicate 
# LLM_RUN_ENV = 'replicate'
# REPLICATE_API_TOKEN = your_replicate_api_token
# LLM_MODEL = 'replicate/meta/meta-llama-3-8b-instruct'