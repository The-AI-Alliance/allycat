{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing HTML Files\n",
    "\n",
    "We will be using **html2parquet transform**\n",
    "\n",
    "References\n",
    "- [html2parquet](https://github.com/IBM/data-prep-kit/tree/dev/transforms/language/html2parquet/python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Data\n",
    "\n",
    "We will process data that is downloaded using [1_crawl_site.ipynb](1_crawl_site.ipynb).\n",
    "\n",
    "We have a couple of crawled HTML files in  `input` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All config is defined here\n",
    "from my_config import MY_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleared  output directory\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(MY_CONFIG.OUTPUT_DIR, ignore_errors=True)\n",
    "shutil.os.makedirs(MY_CONFIG.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print (\"✅ Cleared  output directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: HTML2Parquet\n",
    "\n",
    "Process HTML documents and extract the text in markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:29:30 INFO - html2parquet parameters are : {'output_format': <html2parquet_output_format.MARKDOWN: 'markdown'>, 'favor_precision': <html2parquet_favor_precision.TRUE: 'True'>, 'favor_recall': <html2parquet_favor_recall.TRUE: 'True'>}\n",
      "14:29:30 INFO - pipeline id pipeline_id\n",
      "14:29:30 INFO - code location None\n",
      "14:29:30 INFO - data factory data_ is using local data access: input_folder - input output_folder - output\n",
      "14:29:30 INFO - data factory data_ max_files -1, n_sample -1\n",
      "14:29:30 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.html'], files to checkpoint ['.parquet']\n",
      "14:29:30 INFO - orchestrator html2parquet started at 2025-03-28 14:29:30\n",
      "14:29:30 INFO - Number of files is 91, source profile {'max_file_size': 0.33576393127441406, 'min_file_size': 0.10031604766845703, 'total_file_size': 11.858266830444336}\n",
      "14:29:30 INFO - Completed 1 files (1.1%) in 0.004 min\n",
      "14:29:30 INFO - Completed 2 files (2.2%) in 0.004 min\n",
      "14:29:30 INFO - Completed 3 files (3.3%) in 0.004 min\n",
      "14:29:30 INFO - Completed 4 files (4.4%) in 0.004 min\n",
      "14:29:30 INFO - Completed 5 files (5.49%) in 0.004 min\n",
      "14:29:30 INFO - Completed 6 files (6.59%) in 0.005 min\n",
      "14:29:30 INFO - Completed 7 files (7.69%) in 0.005 min\n",
      "14:29:30 INFO - Completed 8 files (8.79%) in 0.005 min\n",
      "14:29:30 INFO - Completed 9 files (9.89%) in 0.005 min\n",
      "14:29:30 INFO - Completed 10 files (10.99%) in 0.006 min\n",
      "14:29:30 INFO - Completed 11 files (12.09%) in 0.006 min\n",
      "14:29:30 INFO - Completed 12 files (13.19%) in 0.006 min\n",
      "14:29:30 INFO - Completed 13 files (14.29%) in 0.006 min\n",
      "14:29:30 INFO - Completed 14 files (15.38%) in 0.006 min\n",
      "14:29:30 INFO - Completed 15 files (16.48%) in 0.006 min\n",
      "14:29:30 INFO - Completed 16 files (17.58%) in 0.007 min\n",
      "14:29:30 INFO - Completed 17 files (18.68%) in 0.007 min\n",
      "14:29:30 INFO - Completed 18 files (19.78%) in 0.007 min\n",
      "14:29:30 INFO - Completed 19 files (20.88%) in 0.007 min\n",
      "14:29:30 INFO - Completed 20 files (21.98%) in 0.008 min\n",
      "14:29:30 INFO - Completed 21 files (23.08%) in 0.008 min\n",
      "14:29:30 INFO - Completed 22 files (24.18%) in 0.008 min\n",
      "14:29:30 INFO - Completed 23 files (25.27%) in 0.008 min\n",
      "14:29:30 INFO - Completed 24 files (26.37%) in 0.008 min\n",
      "14:29:30 INFO - Completed 25 files (27.47%) in 0.009 min\n",
      "14:29:30 INFO - Completed 26 files (28.57%) in 0.01 min\n",
      "14:29:30 INFO - Completed 27 files (29.67%) in 0.01 min\n",
      "14:29:30 INFO - Completed 28 files (30.77%) in 0.01 min\n",
      "14:29:30 INFO - Completed 29 files (31.87%) in 0.01 min\n",
      "14:29:30 INFO - Completed 30 files (32.97%) in 0.01 min\n",
      "14:29:30 INFO - Completed 31 files (34.07%) in 0.011 min\n",
      "14:29:30 INFO - Completed 32 files (35.16%) in 0.011 min\n",
      "14:29:30 INFO - Completed 33 files (36.26%) in 0.011 min\n",
      "14:29:30 INFO - Completed 34 files (37.36%) in 0.012 min\n",
      "14:29:30 INFO - Completed 35 files (38.46%) in 0.012 min\n",
      "14:29:30 INFO - Completed 36 files (39.56%) in 0.012 min\n",
      "14:29:30 INFO - Completed 37 files (40.66%) in 0.012 min\n",
      "14:29:30 INFO - Completed 38 files (41.76%) in 0.012 min\n",
      "14:29:30 INFO - Completed 39 files (42.86%) in 0.012 min\n",
      "14:29:30 INFO - Completed 40 files (43.96%) in 0.013 min\n",
      "14:29:30 INFO - Completed 41 files (45.05%) in 0.013 min\n",
      "14:29:30 INFO - Completed 42 files (46.15%) in 0.013 min\n",
      "14:29:30 INFO - Completed 43 files (47.25%) in 0.013 min\n",
      "14:29:30 INFO - Completed 44 files (48.35%) in 0.013 min\n",
      "14:29:30 INFO - Completed 45 files (49.45%) in 0.013 min\n",
      "14:29:30 INFO - Completed 46 files (50.55%) in 0.014 min\n",
      "14:29:30 INFO - Completed 47 files (51.65%) in 0.014 min\n",
      "14:29:30 INFO - Completed 48 files (52.75%) in 0.014 min\n",
      "14:29:30 INFO - Completed 49 files (53.85%) in 0.014 min\n",
      "14:29:30 INFO - Completed 50 files (54.95%) in 0.014 min\n",
      "14:29:30 INFO - Completed 51 files (56.04%) in 0.015 min\n",
      "14:29:30 INFO - Completed 52 files (57.14%) in 0.015 min\n",
      "14:29:30 INFO - Completed 53 files (58.24%) in 0.015 min\n",
      "14:29:30 INFO - Completed 54 files (59.34%) in 0.015 min\n",
      "14:29:30 INFO - Completed 55 files (60.44%) in 0.015 min\n",
      "14:29:30 INFO - Completed 56 files (61.54%) in 0.016 min\n",
      "14:29:30 INFO - Completed 57 files (62.64%) in 0.016 min\n",
      "14:29:30 INFO - Completed 58 files (63.74%) in 0.016 min\n",
      "14:29:31 INFO - Completed 59 files (64.84%) in 0.016 min\n",
      "14:29:31 INFO - Completed 60 files (65.93%) in 0.016 min\n",
      "14:29:31 INFO - Completed 61 files (67.03%) in 0.016 min\n",
      "14:29:31 INFO - Completed 62 files (68.13%) in 0.017 min\n",
      "14:29:31 INFO - Completed 63 files (69.23%) in 0.017 min\n",
      "14:29:31 INFO - Completed 64 files (70.33%) in 0.017 min\n",
      "14:29:31 INFO - Completed 65 files (71.43%) in 0.017 min\n",
      "14:29:31 INFO - Completed 66 files (72.53%) in 0.017 min\n",
      "14:29:31 INFO - Completed 67 files (73.63%) in 0.018 min\n",
      "14:29:31 INFO - Completed 68 files (74.73%) in 0.018 min\n",
      "14:29:31 INFO - Completed 69 files (75.82%) in 0.018 min\n",
      "14:29:31 INFO - Completed 70 files (76.92%) in 0.018 min\n",
      "14:29:31 INFO - Completed 71 files (78.02%) in 0.018 min\n",
      "14:29:31 INFO - Completed 72 files (79.12%) in 0.019 min\n",
      "14:29:31 INFO - Completed 73 files (80.22%) in 0.019 min\n",
      "14:29:31 INFO - Completed 74 files (81.32%) in 0.021 min\n",
      "14:29:31 INFO - Completed 75 files (82.42%) in 0.021 min\n",
      "14:29:31 INFO - Completed 76 files (83.52%) in 0.021 min\n",
      "14:29:31 INFO - Completed 77 files (84.62%) in 0.022 min\n",
      "14:29:31 INFO - Completed 78 files (85.71%) in 0.022 min\n",
      "14:29:31 INFO - Completed 79 files (86.81%) in 0.022 min\n",
      "14:29:31 INFO - Completed 80 files (87.91%) in 0.022 min\n",
      "14:29:31 INFO - Completed 81 files (89.01%) in 0.022 min\n",
      "14:29:31 INFO - Completed 82 files (90.11%) in 0.023 min\n",
      "14:29:31 INFO - Completed 83 files (91.21%) in 0.023 min\n",
      "14:29:31 INFO - Completed 84 files (92.31%) in 0.023 min\n",
      "14:29:31 INFO - Completed 85 files (93.41%) in 0.023 min\n",
      "14:29:31 INFO - Completed 86 files (94.51%) in 0.023 min\n",
      "14:29:31 INFO - Completed 87 files (95.6%) in 0.024 min\n",
      "14:29:31 INFO - Completed 88 files (96.7%) in 0.024 min\n",
      "14:29:31 INFO - Completed 89 files (97.8%) in 0.024 min\n",
      "14:29:31 INFO - Completed 90 files (98.9%) in 0.024 min\n",
      "14:29:31 INFO - Completed 91 files (100.0%) in 0.024 min\n",
      "14:29:31 INFO - Done processing 91 files, waiting for flush() completion.\n",
      "14:29:31 INFO - done flushing in 0.0 sec\n",
      "14:29:31 INFO - Completed execution in 0.025 min, execution result 0\n"
     ]
    }
   ],
   "source": [
    "from dpk_html2parquet.transform_python import Html2Parquet\n",
    "\n",
    "x=Html2Parquet(input_folder= MY_CONFIG.INPUT_DIR, \n",
    "               output_folder= MY_CONFIG.OUTPUT_DIR, \n",
    "               data_files_to_use=['.html'],\n",
    "               html2parquet_output_format= \"markdown\"\n",
    "               ).transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Inspect the Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimensions (rows x columns)=  (91, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>document</th>\n",
       "      <th>contents</th>\n",
       "      <th>document_id</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thealliance_ai_working-groups-hardware-enablem...</td>\n",
       "      <td>thealliance_ai_working-groups-hardware-enablem...</td>\n",
       "      <td>[Hardware Enablement Focus Area](/focus-areas/...</td>\n",
       "      <td>698eddd25c4e6e9f172a19ebec695247c0a72e6ec88c66...</td>\n",
       "      <td>1553</td>\n",
       "      <td>2025-03-28T14:29:31.461850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thealliance_ai_blog-open-source-ai-demo-night-...</td>\n",
       "      <td>thealliance_ai_blog-open-source-ai-demo-night-...</td>\n",
       "      <td>On August 8th, The AI Alliance, in collaborati...</td>\n",
       "      <td>7802bb7e50653e6b21f571b28843fd9a4bcf5023eaab3a...</td>\n",
       "      <td>3151</td>\n",
       "      <td>2025-03-28T14:29:30.846980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thealliance_ai_working-groups-applications-and...</td>\n",
       "      <td>thealliance_ai_working-groups-applications-and...</td>\n",
       "      <td>[Applications and Tools Focus Area](/focus-are...</td>\n",
       "      <td>1aaa9d752f74d7abd233abbd8688884c99ea64f575162b...</td>\n",
       "      <td>1565</td>\n",
       "      <td>2025-03-28T14:29:31.422017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thealliance_ai_blog-open-innovation-day-tokyo_...</td>\n",
       "      <td>thealliance_ai_blog-open-innovation-day-tokyo_...</td>\n",
       "      <td>Open innovation in AI software, algorithms, da...</td>\n",
       "      <td>2f82c2d26c751fcb2528eb7c9273ebf3fac4d21b842787...</td>\n",
       "      <td>1304</td>\n",
       "      <td>2025-03-28T14:29:30.839293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thealliance_ai_blog-ai-alliance-skills-and-edu...</td>\n",
       "      <td>thealliance_ai_blog-ai-alliance-skills-and-edu...</td>\n",
       "      <td>By Rebekkah Hogan (Meta), Sowmya Kannan (IBM),...</td>\n",
       "      <td>a8c21ef29afc54923a30393be621693674a1ad23965998...</td>\n",
       "      <td>3615</td>\n",
       "      <td>2025-03-28T14:29:30.633874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  thealliance_ai_working-groups-hardware-enablem...   \n",
       "1  thealliance_ai_blog-open-source-ai-demo-night-...   \n",
       "2  thealliance_ai_working-groups-applications-and...   \n",
       "3  thealliance_ai_blog-open-innovation-day-tokyo_...   \n",
       "4  thealliance_ai_blog-ai-alliance-skills-and-edu...   \n",
       "\n",
       "                                            document  \\\n",
       "0  thealliance_ai_working-groups-hardware-enablem...   \n",
       "1  thealliance_ai_blog-open-source-ai-demo-night-...   \n",
       "2  thealliance_ai_working-groups-applications-and...   \n",
       "3  thealliance_ai_blog-open-innovation-day-tokyo_...   \n",
       "4  thealliance_ai_blog-ai-alliance-skills-and-edu...   \n",
       "\n",
       "                                            contents  \\\n",
       "0  [Hardware Enablement Focus Area](/focus-areas/...   \n",
       "1  On August 8th, The AI Alliance, in collaborati...   \n",
       "2  [Applications and Tools Focus Area](/focus-are...   \n",
       "3  Open innovation in AI software, algorithms, da...   \n",
       "4  By Rebekkah Hogan (Meta), Sowmya Kannan (IBM),...   \n",
       "\n",
       "                                         document_id  size  \\\n",
       "0  698eddd25c4e6e9f172a19ebec695247c0a72e6ec88c66...  1553   \n",
       "1  7802bb7e50653e6b21f571b28843fd9a4bcf5023eaab3a...  3151   \n",
       "2  1aaa9d752f74d7abd233abbd8688884c99ea64f575162b...  1565   \n",
       "3  2f82c2d26c751fcb2528eb7c9273ebf3fac4d21b842787...  1304   \n",
       "4  a8c21ef29afc54923a30393be621693674a1ad23965998...  3615   \n",
       "\n",
       "                date_acquired  \n",
       "0  2025-03-28T14:29:31.461850  \n",
       "1  2025-03-28T14:29:30.846980  \n",
       "2  2025-03-28T14:29:31.422017  \n",
       "3  2025-03-28T14:29:30.839293  \n",
       "4  2025-03-28T14:29:30.633874  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from file_utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(MY_CONFIG.OUTPUT_DIR)\n",
    "\n",
    "print (\"Output dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(5)\n",
    "\n",
    "## To display certain columns\n",
    "#parquet_df[['column1', 'column2', 'column3']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thealliance_ai_working-groups-hardware-enablement_text.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.iloc[0,]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thealliance_ai_working-groups-hardware-enablement_text.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.iloc[0,]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content length: 1553 \n",
      "\n",
      "[Hardware Enablement Focus Area](/focus-areas/hardware-enablement)\n",
      "\n",
      "# Hardware Enablement Working Group\n",
      "\n",
      "## Co-leads\n",
      "\n",
      "- Adam Pingel (IBM)\n",
      "- Amit Sangani (Meta)\n",
      "\n",
      "## Frequently Asked Questions (FAQ)\n",
      "\n",
      "**How can my organization join the AI Alliance as an organizational member?**Please[send a message via our contact form](https://thealliance.ai/contact). Thanks!**How can I join as an individual contributor?**Please complete the[working group application form](https://thealliance.ai/become-a-collaborator). Thanks!**How do I get access to the AI Alliance Slack?**Once your application – as an organization or individual member – has been reviewed and approved, you will be invited to the AI Alliance Slack and receive additional instructions how to join our community.**What if I have additional questions?**[Please contact us](https://thealliance.ai/contact).\n",
      "\n",
      "## Join the Hardware Enablement Working Group\n",
      "\n",
      "By submitting this form, you agree that the AI Alliance will collect and process the personal information you provide to keep you informed about AI Alliance initiatives and enable your involvement in AI Alliance activities. Additionally, you agree that the AI Alliance may share the personal information you provide with its member organizations so that they may communicate with you about AI Alliance initiatives and your involvement in AI Alliance activities.\n",
      "\n",
      "You may withdraw your consent for the processing of your personal information by the AI Alliance. Please [contact us](https://thealliance.ai/contact) to request a permanent deletion.\n"
     ]
    }
   ],
   "source": [
    "## Display markdown text\n",
    "print ('content length:', len(output_df.iloc[0,]['contents']), '\\n')\n",
    "print (output_df.iloc[0,]['contents'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display markdown in pretty format\n",
    "# from IPython.display import Markdown\n",
    "# display(Markdown(output_df.iloc[0,]['contents']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Save the markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 91 md files into 'output'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for index, row in output_df.iterrows():\n",
    "    html_file = row['document']\n",
    "    base_name = os.path.splitext(os.path.basename(html_file))[0]\n",
    "    md_output_file = os.path.join(MY_CONFIG.OUTPUT_DIR, base_name +  '.md')\n",
    "    \n",
    "    with open(md_output_file, 'w') as md_output_file_handle:\n",
    "        md_output_file_handle.write (row['contents'])\n",
    "# -- end loop ---       \n",
    "\n",
    "print (f\"✅ Saved {index+1} md files into '{MY_CONFIG.OUTPUT_DIR}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allychat-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
